
%-----Chapter 5: SensorFusion-------%
\chapter{Sensor Fusion}
In RoboCup every robot works autonomous except a WLAN connection between the teammates. So the whole team can share information to optimize their game.
Through his field of view every robot can bring in some informations about the playing field, other robots and about the ball. Now to optimize the estimation and to exploit the informations from the robots, the team can share this informations in form of a sensor fusion algorithm.
Sensor fusion offers a great opportunity to overcome physical limitations of sensing systems.\cite{IntroSF} 

In the case of RoboCup we need as so called High-level fusion (decision fusion). Methods of decision fusion do not include only the combination of position, edges, corners or lines into a feature map. Rather they imply voting and statistical methods. \cite{IntroSF}

\section{Sensors of the Robots}
The robots comes with a camera with a defined field of view. There are no other sensors or informations with can be used for estimation of the positions. 
There are three types of sensor configuration regarding to sensor fusion. \cite{IntroSF}
\begin{itemize}
	\item Complementary
	\item Competitive
	\item Cooperative
\end{itemize}
In the RoboCup case all the types can occur. The sensor configuration is complementary if a region is  observed by only one robot or camera. And if there are two or more cameras the sensor configuration can be competitive or cooperative.

\section{Principles of Sensor Fusion}
There are several methods 


\section{Dempster-Shafer}

